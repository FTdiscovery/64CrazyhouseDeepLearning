# 64CrazyhouseDeepLearning
A deep learning Crazyhouse chess program that uses a Monte Carlo Tree Search (MCTS) based evaluation system and reinforcement to enhance its play style.

2111 lines

https://ftlearning.wordpress.com/2018/08/13/64-a-crazyhouse-learning-project/

## What is this?

This is a framework of a neural network-based Crazyhouse Chess Engine inspired by the procedures specified by Google DeepMind and their multiple papers on AlphaGo and AlpahZero. This project was initiated in June 15, 2018, following the successful framework of a self-learning Tic Tac Toe engine that managed to solve the game in an hour. You may find the repository for that [here](https://github.com/FTdiscovery/GOMCTS); however, that has yet to be cleaned up for the general public.

Currently, the code is designed for supervised learning (training a network model based on PGN master games), reinforcement learning (having the best network play itself to generate training games, and training new networks from this data to overtake the best network), as well as a self-learning process (start with a randomly initialized or even a pre-trained Pytorch model if desired, from which training games and new networks will be 


### Requirements

### How to Run

### How to Help

Information coming soon!
